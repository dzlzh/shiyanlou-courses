#HBase简介

## 实验简介

我们本节课程将要讲述以下内容：

+ HBase的概述及历史
+ HBase的数据模型
+ HBase的系统架构

## 一、HBase概述

HBase是一个开源的非关系型分布式数据库（NoSQL），它参考了谷歌的BigTable建模，实现的编程语言为 Java。它是Apache软件基金会的Hadoop项目的一部分，运行于HDFS文件系统之上，为 Hadoop 提供类似于BigTable 规模的服务，可以存储海量稀疏的数据，并具备一定的容错性、高可靠性及伸缩性。主要应用场景是实时随机读写超大规模的数据。

HBase在列上实现了BigTable论文提到的压缩算法、内存操作和布隆过滤器。HBase的表能够作为MapReduce任务的输入和输出，可以通过Java API来存取数据，也可以通过REST、Avro或者Thrift的API来访问。

HBase不能取代RDBMS，因为二者的应用场景不同。HBase为了解决海量数据的扩展性，支持简单的增加节点来实现线性扩展，从而在集群上管理海量的非结构化或半结构化的稀疏数据。HBase仅能通过主键（raw key）或主键的range检索数据，支持单行事务。

![Alt text](https://dn-anything-about-doc.qbox.me/hbase/1.jpg)


上图描述Hadoop EcoSystem中的各层系统。其中,HBase位于结构化存储层，Hadoop HDFS为HBase提供了高可靠性的底层存储支持，Hadoop MapReduce为HBase提供了高性能的计算能力，Zookeeper为HBase提供了稳定服务和failover机制。

此外，Pig和Hive还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变的非常简单。 Sqoop则为HBase提供了方便的RDBMS数据导入功能，使得传统数据库数据向HBase中迁移变的非常方便。

##二、HBase历史

Apache HBase最初是Powerset公司为了处理自然语言搜索产生的海量数据而开展的项目。下图展示了HBase的发展历程。

![Alt text](https://dn-anything-about-doc.qbox.me/hbase/2.png)

## 三、HBase数据模型

![Alt text](https://dn-anything-about-doc.qbox.me/hbase/3.png)

+ **行健（Row Key）**：表的主键，表中的记录默认按照行健升序排序
+ **时间戳（Timestamp）**：每次数据操作对应的时间戳，可以看作是数据的版本号
+ **列族（Column Family）**：表在水平方向有一个或者多个列族组成，一个列族中可以由任意多个列组成，列族支持动态扩展，无需预先定义列的数量以及类型，所有列均以二进制格式存储，用户需要自行进行类型转换。所有的列族成员的前缀是相同的，例如“abc:a1”和“abc:a2”两个列都属于abc这个列族。
+ **表和区域（Table&amp;Region）**：当表随着记录数不断增加而变大后，会逐渐分裂成多份，成为区域，一个区域是对表的水平划分，不同的区域会被Master分配给相应的RegionServer进行管理
+ **单元格（Cell）**：表存储数据的单元。由{行健，列（列族:标签），时间戳}唯一确定，其中的数据是没有类型的，以二进制的形式存储。

##四、HBase架构

![Alt text](https://dn-anything-about-doc.qbox.me/hbase/4.jpg)

如上图所示，HBase架构中只有一个Master节点，称HMaster，还有多台RegionServer成为HRegionServer，每个RegionServer包含多个Region。


1. HBase访问接口：Java，REST，Thrift等
1. Master：集群的管理服务器，为RegionServer分配Region，负责RegionServer的负载均衡，处理schema更新请求
1. RegionServer：管理HBase的数据存储，维护Region，处理IO请求。
1. Zookeeper：保证集群的高可用性、存储Region的寻址入口，并实时监控RegionServer的状态，存储HBase的Schema。

可以看到，client访问hbase上数据的过程并不需要Master参与（寻址访问Zookeeper和RegionServer，数据读写访问RegionServer），Master仅仅维护Table和Region的元数据信息，负载很低。

##五、HBase访问接口

1. Native Java API，最常规和高效的访问方式，适合Hadoop MapReduce Job并行批处理HBase表数据
2. HBase Shell，HBase的命令行工具，最简单的接口，适合HBase管理使用
3. Thrift Gateway，利用Thrift序列化技术，支持C++，PHP，Python等多种语言，适合其他异构系统在线访问HBase表数据
4. REST Gateway，支持REST 风格的Http API访问HBase, 解除了语言限制
5. Pig，可以使用Pig Latin流式编程语言来操作HBase中的数据，和Hive类似，本质最终也是编译成MapReduce Job来处理HBase表数据，适合做数据统计
6. Hive，当前Hive的Release版本尚没有加入对HBase的支持，但在下一个版本Hive 0.7.0中将会支持HBase，可以使用类似SQL语言来访问HBase

##六、HBase存储格式

HBase中的所有数据文件都存储在Hadoop HDFS文件系统上，主要包括上述提出的两种文件类型：

1. HFile， HBase中KeyValue数据的存储格式，HFile是Hadoop的二进制格式文件，实际上StoreFile就是对HFile做了轻量级包装，即StoreFile底层就是HFile
2. HLogFile，HBase中WAL（Write Ahead Log） 的存储格式，物理上是Hadoop的Sequence File

##七、HBase应用场景

HBase的优势主要在以下几方面：

1. 海量数据存储
2. 快速随机访问
3. 大量写操作的应用

常见的应用场景

1. 互联网搜索引擎数据存储（BigTable要解决的问题）
2. 审计日志系统
3. 实时系统
4. 消息中心
5. 内容服务系统


##参考文档

+ http://www.ymc.ch/en/introduction-to-hbase
+ http://bigdatariding.blogspot.jp/2013/12/hbase-architecture.html
+ http://baike.baidu.com/view/1993870.htm
+ http://hbase.apache.org/
+ http://www.alidata.org/archives/1509
+ http://zh.wikipedia.org/zh/Apache_HBase
+ http://abloz.com/hbase/book.html



