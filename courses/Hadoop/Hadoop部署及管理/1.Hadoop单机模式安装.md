##一、实验环境说明

###1. 环境登录
无需密码自动登录，系统用户名shiyanlou

###2. 环境介绍

本实验环境采用带桌面的Ubuntu Linux环境，实验中会用到桌面上的程序：

+ XfceTerminal: Linux命令行终端，打开后会进入Bash环境，可以使用Linux命令
+ Firefox：浏览器，可以用在需要前端界面的课程里，只需要打开环境里写的HTML/JS页面即可
+ GVim：非常好用的编辑器，最简单的用法可以参考课程[Vim编辑器](http://www.shiyanlou.com/courses/2)

###3. 环境使用

使用GVim编辑器输入实验所需的代码，然后使用XfceTerminal命令行环境进行编译运行，查看运行结果，运行后可以截图并分享自己的实验成果，实验楼提供的截图是后台截图，无法作弊，可以真实有效证明您已经完成了实验。

实验报告可以在个人主页中查看，其中含有每次实验的截图及笔记，以及每次实验的有效学习时间（指的是在实验桌面内操作的时间，如果没有操作，系统会记录为发呆时间）。这些都是您学习的真实性证明。

###4. 参考文档

本实验参考下列文档内容制作：

+ http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-common/SingleCluster.html
+ http://www.cnblogs.com/kinglau/p/3794433.html


##二、Hadoop启动模式

Hadoop集群有三种启动模式：

+ 单机模式：默认情况下运行为一个单独机器上的独立Java进程，主要用于调试环境
+ 伪分布模式：在单个机器上模拟成分布式多节点环境，每一个Hadoop守护进程都作为一个独立的Java进程运行
+ 完全分布式模式：真实的生产环境，搭建在完全分布式的集群环境

##三、用户及用户组

需要先添加用来运行Hadoop进程的用户组hadoop及用户hadoop。

###1. 添加用户及用户组

创建用户hadoop

```
$ sudo adduser hadoop
```
需要输入shiyanlou的密码。并按照提示输入hadoop用户的密码。

###2. 添加sudo权限

将hadoop用户添加进sudo用户组

```
$ sudo usermod -G sudo hadoop
```

##四、安装及配置依赖的软件包


###1. 安装openssh-server、java、rsync等

```
$ sudo apt-get update
$ sudo apt-get install openssh-server rsync
$ sudo service ssh restart
$ sudo apt-get install openjdk-7-jdk
$ java -version
```

###2. 配置ssh免密码登录

切换到hadoop用户，需要输入添加hadoop用户时配置的密码。后续步骤都将在hadoop用户的环境中执行。

```
$ su -l hadoop
```

配置ssh环境免密码登录。

```
$ ssh-keygen -t rsa -P ""
```

在/home/hadoop/.ssh目录下生成了id_rsa（私钥）和id_rsa.pub（公钥）两个文件,将公钥追加到authorized_keys中，该文件保存所有允许以当前用户身份登录到ssh客户端用户的公钥内容。

```
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```

验证登录本机是否还需要密码，配置正确的话是可以不需密码登录的。
```
$ ssh localhost
```

##五、下载并安装Hadoop

在hadoop用户登录的环境中进行下列操作：

###1. 下载Hadoop 2.6.0

```
$ wget http://labfile.oss.aliyuncs.com/hadoop-2.6.0.tar.gz
```

###2. 解压并安装

```
$ tar zxvf hadoop-2.6.0.tar.gz
$ sudo mv hadoop-2.6.0 /usr/local/hadoop
$ sudo chmod 774 /usr/local/hadoop
```

###3. 配置Hadoop
```
$ vim /home/hadoop/.bashrc
```

在/home/hadoop/.bashrc文件末尾添加下列内容：

```
#HADOOP START
export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
export HADOOP_INSTALL=/usr/local/hadoop
export PATH=$PATH:$HADOOP_INSTALL/bin
export PATH=$PATH:$HADOOP_INSTALL/sbin
export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_HOME=$HADOOP_INSTALL
export HADOOP_HDFS_HOME=$HADOOP_INSTALL
export YARN_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_INSTALL/lib"
#HADOOP END
```

保存退出后，激活新加的环境变量
```
$ source ~/.bashrc
```

至此，Hadoop单机模式安装完成，可以通过下述步骤的测试来验证安装是否成功。

##六、测试验证

创建输入的数据，暂时采用/etc/protocols文件作为测试

```
$ cd /usr/local/hadoop
$ sudo mkdir input
$ sudo cp /etc/protocols ./input
```

执行Hadoop WordCount应用（词频统计）

```
$ bin/hadoop jar share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-2.6.0-sources.jar org.apache.hadoop.examples.WordCount input output
```

查看生成的单词统计数据

```
$ cat output/*
```

**注意**：如果要继续下一节“伪分布式部署”实验，请勿停止本实验环境，直接点击文档上方的“下一个实验”按钮进入，因为伪分布式部署模式需要在单机模式基础上进行配置。



##七、小结

本实验中介绍了Hadoop单机模式的安装方法，并运行wordcount进行基本测试。

##八、思考题

请使用hadoop的wordcount对日志文件/var/log/dpkg.log进行词频统计。

实验中有任何问题欢迎到[实验楼问答](http://www.shiyanlou.com/questions)提问。




